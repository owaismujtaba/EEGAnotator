{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************Loading Audio data***************************\n",
      "*********************************************************************************\n",
      "***************************Loading .xdf file***************************\n",
      "*******************************Completed*******************************\n",
      "***************************Preprocessing Audio data***************************\n",
      "***************************Started Bundling markers and audio timestamps***************************\n",
      "*********************************************************************************\n",
      "***************************Loading .edf file***************************\n",
      "C:\\DeepRESTORE\\EEGAnotator\\Data\\F10\\PictureNaming\\eeg\\f10.edf\n",
      "Extracting EDF parameters from C:\\DeepRESTORE\\EEGAnotator\\Data\\F10\\PictureNaming\\eeg\\f10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "*******************************Completed*******************************\n",
      "Checking for Interruptions\n",
      "No interruptions detected.\n"
     ]
    }
   ],
   "source": [
    "from src.code.audio import AUDIO_DATA\n",
    "from src.code.eeg import EEG_DATA\n",
    "edf_path = 'C:\\DeepRESTORE\\EEGAnotator\\Data\\F10\\PictureNaming\\eeg\\\\f10.edf'\n",
    "xdf_path = 'C:\\DeepRESTORE\\\\25-05-2024\\EEGAnotator\\Data\\F10\\PictureNaming\\\\xdf\\\\f10.xdf'\n",
    "#edf_path = '/home/owais/GitHub/21-05-2024/EEGAnotator/F10/PictureNaming/eeg/sample.edf'\n",
    "#xdf_path = '/home/owais/GitHub/21-05-2024/EEGAnotator/F10/PictureNaming/xdf/sample.xdf'\n",
    "audio = AUDIO_DATA(filepath_xdf=xdf_path)\n",
    "eeg = EEG_DATA(edf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.65640762e+09, 1.65640762e+09, 1.65640762e+09, ...,\n",
       "       1.65640929e+09, 1.65640929e+09, 1.65640929e+09])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.MARKERS_TIME_STAMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import EEG_AUDIO_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m deeg_audio_data \u001b[38;5;241m=\u001b[39m \u001b[43mEEG_AUDIO_DATA\u001b[49m\u001b[43m(\u001b[49m\u001b[43meeg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\DeepRESTORE\\25-05-2024\\EEGAnotator\\src\\utils.py:42\u001b[0m, in \u001b[0;36mEEG_AUDIO_DATA.__init__\u001b[1;34m(self, eeg_data_obj, audio_data_object)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_marker_start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mMARKERS_TIME_STAMPS[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNearestEEGStartPointToAudio \u001b[38;5;241m=\u001b[39m find_closest_starting_point_in_eeg(\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meeg\u001b[38;5;241m.\u001b[39mEVENTS, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_marker_start_time\n\u001b[0;32m     40\u001b[0m )\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMappingEEGEventsWithMarkers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_eeg_actions_to_marker_words\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNearestEEGStartPointToAudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meeg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEVENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMARKERS_TIME_STAMPS\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\DeepRESTORE\\25-05-2024\\EEGAnotator\\src\\utils.py:75\u001b[0m, in \u001b[0;36mEEG_AUDIO_DATA.map_eeg_actions_to_marker_words\u001b[1;34m(self, start_timestamp_eeg, eeg_events, markers_words_timestamps)\u001b[0m\n\u001b[0;32m     72\u001b[0m action, start_time, end_time, start_index, end_index, duration \u001b[38;5;241m=\u001b[39m event\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(word_index, \u001b[38;5;28mlen\u001b[39m(markers_words_timestamps)):\n\u001b[1;32m---> 75\u001b[0m     marker, word, time, audio_index \u001b[38;5;241m=\u001b[39m markers_words_timestamps[index]\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;241m==\u001b[39m marker:\n\u001b[0;32m     78\u001b[0m         result\u001b[38;5;241m.\u001b[39mappend([marker, word, start_time, end_time, start_index, end_index,audio_index, duration, time])\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "deeg_audio_data = EEG_AUDIO_DATA(eeg, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2022-06-28T11:13:39.154')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.MARKERS_START_TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
