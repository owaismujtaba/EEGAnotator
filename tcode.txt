import bisect
import json
import mne
import numpy as np
import os
import pyxdf
from scipy.io.wavfile import write
import tkinter as tk
from tkinter.filedialog import askopenfilename
ventana_open_files = tk.Tk()
path_edf = tk.StringVar(value = "")
path_xdf = tk.StringVar(value = "")
path_segmented_data = tk.StringVar(value = "")
def abrir_archivo_edf():
    archivo_abierto_edf = askopenfilename(initialdir = "/",
                                                 title = "Select EDF file",
                                               filetypes = (("edf files","*.edf"),("all files","*.*")))
    path_edf.set(value=archivo_abierto_edf)
    label_edf.config(fg = "black",text= path_edf.get())

def abrir_archivo_xdf():
    archivo_abierto_xdf = askopenfilename(initialdir = "/",
                                                 title = "Select XDF file",
                                                 filetypes = (("xdf files","*.xdf"),("all files","*.*")))
    path_xdf.set(value=archivo_abierto_xdf)
    label_xdf.config(fg = "black",text= path_xdf.get())
def seleccionar_carpeta_segmented_data():
  
    folder = tk.filedialog.askdirectory()
    path_segmented_data.set(value = folder)
    label_path_segmented_data.config(fg = "black",text = path_segmented_data.get())

def close_window_open_files ():
    if(len(path_edf.get()) > 0 and len(path_xdf.get())> 0 and len(path_segmented_data.get())>0):
        ventana_open_files.quit()
        ventana_open_files.destroy()
        win = tk.Tk()
        #Set the geometry of tkinter frame
        win.geometry("750x270")
        #Initialize a Label widget
        tk.Label(win, text= "Cargando datos.\n Esto llevará algunos minutos.",
        font=('Helvetica 20 bold')).pack(pady=20)
        #Automatically close the window after 3 seconds
        win.after(3000,lambda:win.destroy())
        win.mainloop()  
    else:   
    
        if(len(path_edf.get()) == 0):
            label_edf.config(fg = "red",text="Seleccione el archivo .edf " )
            
        if(len(path_xdf.get()) == 0):
            label_xdf.config(fg = "red",text="Seleccione el archivo .xdf " )    
    
        if(len(path_segmented_data.get()) == 0):
            label_path_segmented_data.config(fg = "red",
                                             text="Seleccione una carpeta donde guardar los datos segmentados " ) 
            
            


button_edf = tk.Button(ventana_open_files,text = "Seleccionar archivo edf",command = abrir_archivo_edf)
button_edf.pack()


label_edf = tk.Label(ventana_open_files,text = path_edf.get())
label_edf.pack()
label_edf.config(fg="black",    # Foreground
             font=("Verdana",12))

button_xdf = tk.Button(ventana_open_files,text = "Seleccionar archivo xdf",command = abrir_archivo_xdf)
button_xdf.pack()


label_xdf = tk.Label(ventana_open_files,text = path_xdf.get())
label_xdf.pack()
label_xdf.config(fg="black",    # Foreground
             font=("Verdana",12))


button_segmented_data = tk.Button(ventana_open_files,
                               text = "Seleccionar carpeta donde guardar los datos segmentados",command = seleccionar_carpeta_segmented_data)
button_segmented_data.pack()


label_path_segmented_data = tk.Label(ventana_open_files,text = path_segmented_data.get())
label_path_segmented_data.pack()
label_path_segmented_data.config(fg="black",    # Foreground
             font=("Verdana",12))


button = tk.Button(master = ventana_open_files,text = "Confirmar selección",command = close_window_open_files)
button.pack(side = tk.BOTTOM)  



ventana_open_files.mainloop()

path_edf = path_edf.get()
path_xdf = path_xdf.get()

# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#


# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ------------- Identificar inicio del experimento en .edf -------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#

raw = mne.io.read_raw_edf(path_edf) ##EEG, triggers
data, header = pyxdf.load_xdf(path_xdf) ## AUDIO, Markers

print("datos cargados")
frec = raw.info["sfreq"] # sampling frequency

trig = -raw["TRIG"][0][0].copy()
trig2 = (trig/trig.max())*255 # triggers normalized

pausas_xdf = [] # duración de cada pausa en el archivo .xdf 
tiempos_pausas_xdf = [] # instante de tiempo en que aparecen las pausas
                        # de la lista anterior

# En la ultima verson, no son pausas (>3 segundos) sino que se 
# emplean todos los marcadores (>1 segundos)

# En el .xdf, el instante de inicio del experimento
# no se corresponde con t = 0 si no con t = time0
# por lo que, para obtener los tiempos correctos 
# se debe restar time0 a todo.
time0 = data[0]["time_stamps"][0]

aux = 0

  
i=0
for stream in data:
    y = stream['time_series']

    if isinstance(y, list):
       
        for timestamp, marker in zip(stream['time_stamps'], y):
                            
            abstimestamp = timestamp - time0
            
            if(abstimestamp-aux > 1): 
            
                pausas_xdf.append(abstimestamp-aux)
                tiempos_pausas_xdf.append(aux)
                
            aux = abstimestamp 
            i+=1
            
            
            
for stream in data:
    y = stream['time_series']

    if isinstance(y, list):
        
        for timestamp, marker in zip(stream['time_stamps'], y):
            if(marker[0] == "ExperimentStarted"):
                time_start = timestamp
                break
                
for stream in data:
    y = stream['time_series']

    if isinstance(y, list):
    
        for timestamp, marker in zip(stream['time_stamps'], y):
            if(marker[0] == "ExperimentEnded"):
                time_end = timestamp 
                                
                break
            
i = 0
# Aqui se trata de extraer los instantes de tiempo en que aparecen los triggers    
tiempos_utiles = []

while(i<len(trig2)):
    
    tiempos_utiles.append(i/frec)
    aux = trig2[i]
    i+=1
    while(trig2[i] == aux):
        i+=1
        
        if(i>len(trig2)-2):
            break
        
    if(i>len(trig2)-2):
            break
            
pausas_edf = [tiempos_utiles[i+1]-tiempos_utiles[i] for i in range(len(tiempos_utiles)-1)
              if tiempos_utiles[i+1]-tiempos_utiles[i]>1]



tiempos_pausas_edf = []
for i in range(len(tiempos_utiles)-1):
    
    if(tiempos_utiles[i+1]-tiempos_utiles[i]>1):
     #if(tiempos_utiles[i+1]-tiempos_utiles[i]>3 and tiempos_utiles[i+1]-tiempos_utiles[i]<10):   
        tiempos_pausas_edf.append(tiempos_utiles[i])
        
tiempos_entre_pausas_xdf = [tiempos_pausas_xdf[i]-tiempos_pausas_xdf[i-1] for i in range(1,len(tiempos_pausas_xdf),1)]
tiempos_entre_pausas_edf = [tiempos_pausas_edf[i]-tiempos_pausas_edf[i-1] for i in range(1,len(tiempos_pausas_edf),1)]
# El indice de inicio será el que encontremos que produce el menor error al 
# comparar los tiempos entre pausas del .xdf con los del .edf

error_coincidencias = []
for i in range(len(tiempos_entre_pausas_edf)-len(tiempos_entre_pausas_xdf)+1):
    error_coincidencias.append(sum([abs(tiempos_entre_pausas_edf[i+j]-tiempos_entre_pausas_xdf[j]) for j in range(len(tiempos_entre_pausas_xdf))]))
   


i_0 = np.where(error_coincidencias == np.amin(error_coincidencias))[0][0]
tiempo_inicio_edf = tiempos_entre_pausas_edf[i_0-1] + tiempos_pausas_edf[i_0-1] - tiempos_pausas_xdf[0]



t_inicial = int(frec*(tiempo_inicio_edf))

trig_experiment_started = 16
interval_len = 0.25 # se buscará el trigger de inicio en el intervalo de tiempo [t_inicial-interval_len,t_inicial+interval_len]
i_start = -1
for i in range(t_inicial-int(frec*interval_len),t_inicial+int(frec*interval_len),1):

    if(trig2[i]>1):
        
        if(abs(trig2[i]-trig_experiment_started)<2):
            i_start = i
            break
        
        i_start = i
        break

# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#

# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ---------------------- Segmentar y guardar el audio ----------------------- #
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#

# Here it will be saved segmented data
path_segmented_data = path_segmented_data.get()+"/" 
path_audios = path_segmented_data + "/AUDIO/"



if(not os.path.isdir(path_audios)):
    
    os.mkdir(path_audios)

# time_0 = (tiempo absoluto del inicio del experimento) - 
#          (tiempo absoluto del inicio de la grabacion)    


time_0 = time0 - float(data[1]["footer"]["info"]["first_timestamp"][0])
s_rate = int(float(data[1]["info"]["nominal_srate"][0]))


def locate_pos(available_freqs, target_freq):
    pos = bisect.bisect_right(available_freqs, target_freq)
    if pos == 0:
        return 0
    if pos == len(available_freqs):
        return len(available_freqs)-1
    if abs(available_freqs[pos]-target_freq) < abs(available_freqs[pos-1]-target_freq):
        return pos
    else:
        return pos-1  



streamToPosMapping = {}
for pos in range(0,len(data)):
    
    stream = data[pos]['info']['name']
    streamToPosMapping[stream[0]] = pos
    
#Load Audio
audio = data[streamToPosMapping['MyAudioStream']]['time_series']


# Save complete audio 
write(path_segmented_data + "audio_completo.wav",s_rate,audio)  

           
# Para segmentar el audio, quitamos lo que viene antes del inicio del experimento.       
audio = audio[int(time_0 * s_rate) : ]     



# Este codigo guarda los audios de los bloques en voz alta y NO guarda los que
# corresponden a bloques imaginados.

audio_aux = audio
block_num = 0
num_orden = 0


for stream in data:
    y = stream['time_series']
    aux = False
    t_0 = 0
    t_final = 0
    if isinstance(y, list):
        
        for timestamp, marker in zip(stream['time_stamps'], y):
            #print(f'Marker "{marker[0]}" @ {timestamp-time0:.2f}s')
            
            if(marker[0] == "StartBlockSaying"):
                aux = True
                
            if(marker[0] =="StartBlockThinking" ):
                aux = False
                
                
            if(marker[0].startswith("StartBlock")):
                block_num +=1
            
            if(marker[0].startswith("StartReading")):
                num_orden+=1
                
                        
            if(aux):
                
                if(marker[0].startswith("StartSaying")):
                    t_0 = timestamp-time0
                if(marker[0].startswith("EndSaying")): 
                    t_final = timestamp-time0

                    
                    audio_aux = audio[int(t_0*s_rate) : int(t_final*s_rate)]
                    #VCV
                    #write(path_audios+str(num_orden).zfill(3)+"_"+marker[0][-3:]+"_"+str(block_num)+".wav",s_rate, audio_aux)
                    #Picture Naming
                    write(path_audios+str(num_orden).zfill(3)+"_"+marker[0].split(":")[1]+"_"+str(block_num)+".wav",s_rate, audio_aux)

# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#

win = tk.Tk()

#Set the geometry of tkinter frame
win.geometry("750x270")

#Initialize a Label widget
tk.Label(win, text= "Audio segmentado.\n Segmentando EEG...",
font=('Helvetica 20 bold')).pack(pady=20)

#Automatically close the window after 3 seconds
win.after(3000,lambda:win.destroy())

win.mainloop()





time_aux = i_start / frec #in seconds. trigger position divided by frecuency
n_channels = len(raw.ch_names)

# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ---------------------Seleccionamos los canales------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#

window_pick_channels = tk.Tk()
channels_boolean =[tk.BooleanVar(value = False) for i in range(n_channels)] 

off_color = "red"
on_color = "green"

def on_check():    #this function will run on click on checkbutton
    
    for i in range(n_channels):

        if (channels_boolean[i].get()):
            button_list[i]["fg"] = on_color    
    
        else:
            button_list[i]["fg"] = off_color



button_list = []
    
for i in range(n_channels):
    
    button = tk.Checkbutton(window_pick_channels,text = raw.ch_names[i],onvalue = True,offvalue = False,variable = channels_boolean[i],
                         font = ("Verdana",18),command = on_check,fg=off_color)
    
    button.grid(row = i%15,column= i//15)
    button_list.append(button)


def close_window_pick_channels():
    
    window_pick_channels.quit()
    window_pick_channels.destroy()
    
    
tk.Button(window_pick_channels,text = "Confirmar selección de canales",command = close_window_pick_channels).grid(row = 30,column = 35)

window_pick_channels.mainloop()



good_channels = [raw.ch_names[i] for i in range(n_channels)
                 if( channels_boolean[i].get())]
channels_to_drop = [raw.ch_names[i] for i in range(n_channels)  
                    if(not channels_boolean[i].get())]


  

raw.drop_channels(channels_to_drop)


# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#


# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# -----------------------Segmentamos los datos -------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#


    
onset = []   # instante de tiempo en que comienzan las epochs            
description = [] # descripcion de cada epoch 
duration = [] # duracion de cada epoch

path_eeg = path_segmented_data+"/EEG/"
if(not os.path.isdir(path_eeg)):
    
    os.mkdir(path_eeg)


if(True):
    
    # PRIMERO READ
    path_segmented_data_aux = path_eeg + "0. only read part and only say part/"
    
    if(not os.path.isdir(path_segmented_data_aux)):
        
        os.mkdir(path_segmented_data_aux)
    
    path_segmented_data_aux+="Read/"
    
    if(not os.path.isdir(path_segmented_data_aux)):
        
        os.mkdir(path_segmented_data_aux)
        
    for stream in data:
        y = stream['time_series']
    
        if isinstance(y, list):
        # list of strings, draw one vertical line for each marker
            for timestamp, marker in zip(stream['time_stamps'], y):
                aux = False
                abstimestamp = timestamp - time0 + time_aux
                
                if(marker[0].startswith("StartBlockTh")):
                    str_aux = "_I"
                if(marker[0].startswith("StartBlockS")):
                    str_aux = "_S"
                
                if(marker[0].startswith("StartReading")):
                
                    onset.append(abstimestamp)
                    #VCV
                    #description.append(marker[0][-3:]+str_aux)
                    #Picture Naming
                    description.append(marker[0].replace("StartReading","")+str_aux) 
                    time_start_aux = abstimestamp
            
                if(marker[0].startswith("EndReading")):
                    duration.append(abstimestamp - time_start_aux)  
                
                
    my_annot = mne.Annotations(onset=onset,  # in seconds
                               duration=duration,  # in seconds, too
                               description= description)
    raw.set_annotations(my_annot)
    events_from_annot, event_dict = mne.events_from_annotations(raw)


    # For the moment, we will use the average duration because all epochs must have exactly the same duration
    t_min = 0.0
    t_max = np.mean(duration)
    epochs = mne.Epochs(raw, events_from_annot, tmin=t_min, tmax=t_max, baseline=(None, None))

    # Saving the data

    for i in range(len(description)):
       
        num_orden_str = str(i+1).zfill(3)
        np.save(path_segmented_data_aux+str(num_orden_str)+"_"+description[i].replace(":","")+".npy",epochs[i].get_data())
          
        
        
    # DESPUÉS SAY            
    onset = []                
    description = []
    duration = []
            
         
    path_segmented_data_aux = path_eeg + "0. only read part and only say part/Say/"
    if(not os.path.isdir(path_segmented_data_aux)):
        
        os.mkdir(path_segmented_data_aux)
    #print(path_segmented_data_aux)        
    for stream in data:
        y = stream['time_series']
    
        if isinstance(y, list):
        # list of strings, draw one vertical line for each marker
            for timestamp, marker in zip(stream['time_stamps'], y):
                aux = False
                abstimestamp = timestamp - time0 + time_aux
                
                if(marker[0].startswith("StartBlockTh")):
                    str_aux = "_I"
                if(marker[0].startswith("StartBlockS")):
                    str_aux = "_S"        
            
 
                if(marker[0].startswith("StartSaying")):
                
                    onset.append(abstimestamp)
                    #VCV
                    #description.append(marker[0][-3:]+str_aux)
                    #Picture Naming
                    description.append(marker[0].replace("StartSaying","")+str_aux) 
                    time_start_aux = abstimestamp
            
                if(marker[0].startswith("EndSaying")):
                    duration.append(abstimestamp - time_start_aux)
    
    my_annot = mne.Annotations(onset=onset,  # in seconds
                               duration=duration,  # in seconds, too
                               description= description)
    raw.set_annotations(my_annot)
    events_from_annot, event_dict = mne.events_from_annotations(raw)
 
    # For the moment, we will use the average duration because all epochs must have exactly the same duration
    t_min = 0.0
    t_max = np.mean(duration)
    epochs = mne.Epochs(raw, events_from_annot, tmin=t_min, tmax=t_max, baseline=(None, None))

    # Saving the data

    for i in range(len(description)):

        
        num_orden_str = str(i+1).zfill(3)
        np.save(path_segmented_data_aux+str(num_orden_str)+"_"+description[i].replace(":","")+".npy",epochs[i].get_data())
if(True):
    
    onset = []                
    description = []
    duration = []
    
    path_segmented_data_aux = path_eeg + "1. fixation cross (end of previous say or imagine to start of current read)/"
    if(not os.path.isdir(path_segmented_data_aux)):
        
        os.mkdir(path_segmented_data_aux)
    
    aux = ""
    num_bloque = 1

    trial_previo = ""
    str_aux = ""
    
    for stream in data:
        y = stream['time_series']
    
        if isinstance(y, list):
       
            for timestamp, marker in zip(stream['time_stamps'], y):
                if(marker[0]=="ExperimentEnded"):break
                abstimestamp = timestamp - time0 + time_aux
                if(marker[0].startswith("StartBlockTh")):
                    str_aux = "_I"
                if(marker[0].startswith("StartBlockS")):
                    str_aux = "_S"
                if(marker[0].startswith("EndSaying")):
                
                    time_start_aux = abstimestamp
                    #VCV
                   # aux = marker[0][-3:]
                    #Picture Naming
                    aux = marker[0]
                if(marker[0].startswith("StartReading") and aux != "" and trial_previo.startswith("EndSaying")):
                    onset.append(time_start_aux)
                    duration.append(abstimestamp - time_start_aux)     
                    
            
            
            ##Casos patologicos que no tienen end read previo
            
            
                if(marker[0].startswith("StartBlock")):
                
                    onset.append(abstimestamp)
                    time_start_aux = abstimestamp
                    num_bloque+=1
                    
                if(marker[0].startswith("StartRead") and trial_previo.startswith("StartBlock")):
                    duration.append(abstimestamp - time_start_aux)  
                    
                    
                trial_previo = marker[0]
            
    for stream in data:
        y = stream['time_series']
    
        if isinstance(y, list):
       
            for timestamp, marker in zip(stream['time_stamps'], y):
                
                if(marker[0].startswith("StartBlockTh")):
                    str_aux = "_I"
                if(marker[0].startswith("StartBlockS")):
                    str_aux = "_S"
            
                if(marker[0].startswith("StartRead")):
                    #VCV
                    #description.append(marker[0][-3:]+str_aux)
                    #Picture Naming
                    description.append(marker[0].replace("StartReading","")+str_aux)    


    my_annot = mne.Annotations(onset=onset,  # in seconds
                               duration=duration,  # in seconds, too
                               description= description)
    raw.set_annotations(my_annot)
    events_from_annot, event_dict = mne.events_from_annotations(raw)

    # For the moment, we will use the average duration because all epochs must have exactly the same duration
    t_min = 0.0
    t_max = np.mean(duration)
    epochs = mne.Epochs(raw, events_from_annot, tmin=t_min, tmax=t_max, baseline=(None, None))

    # Saving the data

    for i in range(len(description)):

        
        num_orden_str = str(i+1).zfill(3)
        np.save(path_segmented_data_aux+str(num_orden_str)+"_"+description[i].replace(":","")+".npy",epochs[i].get_data())    
if(True):
    
    onset = []                
    description = []
    duration = []
    
    path_segmented_data_aux = path_eeg + "2. Delay between read and say (end of current read to start of current say or imagine)/"
    if(not os.path.isdir(path_segmented_data_aux)):
        
        os.mkdir(path_segmented_data_aux)
    str_aux = ""

    for stream in data:
        y = stream['time_series']
    
        if isinstance(y, list):
        # list of strings, draw one vertical line for each marker
            for timestamp, marker in zip(stream['time_stamps'], y):
            
                abstimestamp = timestamp - time0 + time_aux
            
                if(marker[0].startswith("StartBlockTh")):
                
                    str_aux = "Thinked"
            
                if(marker[0].startswith("StartBlockS")):
            
                    str_aux = ""
            
                if(marker[0].startswith("EndReading")):
                
                    onset.append(abstimestamp)
                    
                    time_start_aux = abstimestamp
                
                if(marker[0].startswith("StartSaying")):
                    duration.append(abstimestamp - time_start_aux) 
                    
                    
                    
    for stream in data:
        y = stream['time_series']
    
        if isinstance(y, list):
       
            for timestamp, marker in zip(stream['time_stamps'], y):
                
                if(marker[0].startswith("StartBlockTh")):
                    str_aux = "_I"
                if(marker[0].startswith("StartBlockS")):
                    str_aux = "_S"
            
                if(marker[0].startswith("StartRead")):
                    #VCV
                    #description.append(marker[0][-3:]+str_aux)
                    #Picture Naming
                    description.append(marker[0].replace("StartReading","")+str_aux)                     
                    
    my_annot = mne.Annotations(onset=onset,  # in seconds
                               duration=duration,  # in seconds, too
                               description= description)
    raw.set_annotations(my_annot)
    events_from_annot, event_dict = mne.events_from_annotations(raw)
 
    # For the moment, we will use the average duration because all epochs must have exactly the same duration
    t_min = 0.0
    t_max = np.mean(duration)
    epochs = mne.Epochs(raw, events_from_annot, tmin=t_min, tmax=t_max, baseline=(None, None))

    # Saving the data

    for i in range(len(description)):

        
        num_orden_str = str(i+1).zfill(3)
        np.save(path_segmented_data_aux+str(num_orden_str)+"_"+description[i].replace(":","")+".npy",epochs[i].get_data())
#3. Entire trial without fixation cross (start of read to end of say)
if(True):
    
    onset = []                
    description = []
    duration = []
    
    path_segmented_data_aux = path_eeg + "3. Entire trial without fixation cross (start of read to end of say)/"
    if(not os.path.isdir(path_segmented_data_aux)):
        
        os.mkdir(path_segmented_data_aux)
    str_aux = ""

    for stream in data:
        y = stream['time_series']
    
        if isinstance(y, list):
        
            for timestamp, marker in zip(stream['time_stamps'], y):
                
                abstimestamp = timestamp - time0 + time_aux
            
                if(marker[0].startswith("StartBlockTh")):
                
                    str_aux = "_I"
            
                if(marker[0].startswith("StartBlockS")):
            
                    str_aux = "_S"
            
            
                if(marker[0].startswith("StartReading")):
                
                    onset.append(abstimestamp)
                    #VCV
                    #description.append(marker[0][-3:]+str_aux)
                    #Picture Naming
                    description.append(marker[0].replace("StartReading","")+str_aux) 
                    time_start_aux = abstimestamp
                
                if(marker[0].startswith("EndSaying")):
                    duration.append(abstimestamp - time_start_aux)  
                    
                    
    my_annot = mne.Annotations(onset=onset,  # in seconds
                               duration=duration,  # in seconds, too
                               description= description)
    raw.set_annotations(my_annot)
    events_from_annot, event_dict = mne.events_from_annotations(raw)

    # For the moment, we will use the average duration because all epochs must have exactly the same duration
    t_min = 0.0
    t_max = np.mean(duration)
    epochs = mne.Epochs(raw, events_from_annot, tmin=t_min, tmax=t_max, baseline=(None, None))

    # Saving the data

    for i in range(len(description)):

        
        num_orden_str = str(i+1).zfill(3)
        np.save(path_segmented_data_aux+str(num_orden_str)+"_"+description[i].replace(":","")+".npy",epochs[i].get_data())                    
#4. Entire trial with fixation cross (end of previous say to end of current say)

if(True):
    
    onset = []                
    description = []
    duration = []
    
    path_segmented_data_aux = path_eeg + "4. Entire trial with fixation cross (end of previous say to end of current say)/"
    if(not os.path.isdir(path_segmented_data_aux)):
        
        os.mkdir(path_segmented_data_aux)
    num_bloque = 1

    onset_aux = []
    description_aux = []


    for stream in data:
        y = stream['time_series']
    
        if isinstance(y, list):
        
            for timestamp, marker in zip(stream['time_stamps'], y):
            
                abstimestamp = timestamp - time0 + time_aux
            
                if(marker[0].startswith("StartBlockS")):
                
                    onset_aux.append(abstimestamp)
                    description_aux.append(marker[0])
                
                if(marker[0].startswith("StartBlockT")):
                
                    onset_aux.append(abstimestamp)
                    description_aux.append(marker[0])
                
            
            
                if(marker[0].startswith("EndSaying")):
                
                    onset_aux.append(abstimestamp)
                    description_aux.append(marker[0])  

                
    j = 0
    num_bloque = 1
    say_or_think = ""
    for i in range(len(description_aux)-1):
        if("Thinkin" in description_aux[i]):
            say_or_think = "Thinking"
        
        if("BlockSaying" in description_aux[i]):
            say_or_think = "Saying"
        
      
        if(not description_aux[i+1].startswith("StartBlock")):
         
            description_i = description_aux[i]
            description_i_1=description_aux[i+1]
        
            if (say_or_think == "Thinking"):
                description_i = description_aux[i].replace("Saying","Thinking")
                description_i_1=description_aux[i+1].replace("Saying","Thinking")
            
            
            #print(j,description_i+"_to_"+description_i_1)
        
            onset.append(onset_aux[i])
            duration.append(onset_aux[i+1]-onset_aux[i])
            j+=1

            
            
    for stream in data:
        y = stream['time_series']
    
        if isinstance(y, list):
       
            for timestamp, marker in zip(stream['time_stamps'], y):
                
                if(marker[0].startswith("StartBlockTh")):
                    str_aux = "_I"
                if(marker[0].startswith("StartBlockS")):
                    str_aux = "_S"
            
                if(marker[0].startswith("StartRead")):
                    #VCV
                    #description.append(marker[0][-3:]+str_aux)
                    #Picture Naming
                    description.append(marker[0].replace("StartReading","")+str_aux)   
                    
    my_annot = mne.Annotations(onset=onset,  # in seconds
                               duration=duration,  # in seconds, too
                               description= description)
    raw.set_annotations(my_annot)
    events_from_annot, event_dict = mne.events_from_annotations(raw)
    

    # For the moment, we will use the average duration because all epochs must have exactly the same duration
    t_min = 0.0
    t_max = np.mean(duration)
    epochs = mne.Epochs(raw, events_from_annot, tmin=t_min, tmax=t_max, baseline=(None, None))

    # Saving the data

    for i in range(len(description)):

        
        num_orden_str = str(i+1).zfill(3)
        np.save(path_segmented_data_aux+str(num_orden_str)+"_"+description[i].replace(":","")+".npy",epochs[i].get_data())                    
                    

# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#



# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# -------------Recuperamos la informacion importante -------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#


data_to_save = {}

data_to_save["Inicio_experimento_.edf_(en_segundos)"] = tiempo_inicio_edf
data_to_save["Inicio_experimento_.edf"] = str(round(tiempo_inicio_edf//60))+"'"+str(round(tiempo_inicio_edf%60,2))+"''"
data_to_save["Duracion_experimento_(en_segundos)"] = time_end-time_start
data_to_save["Duracion_experimento"] = str((round(time_end-time_start)//60))+"'"+str(round((time_end-time_start)%60,2))+"''"
data_to_save["Fin_experimento_.edf_(en_segundos)"] = tiempo_inicio_edf + (time_end-time_start)
data_to_save["Fin_experimento_.edf"] =str(round((tiempo_inicio_edf + (time_end-time_start))//60,2))+ "'" +str(round((tiempo_inicio_edf + (time_end-time_start))%60,2))+"''"
data_to_save["Instante_inicio en_archivo_de_audio"] = time_0
data_to_save["Indice_inicio_.edf"] = i_start
data_to_save["Canales_empleados"] = good_channels


with open(path_segmented_data+ 'summary.json', 'w') as file:
    json.dump(data_to_save, file, indent=4)


# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#
# ----------------------------------------------------------------------------#



#ventana_input_time = tk.Tk()

#label_minutes = tk.Label(ventana_input_time,text = "Minuto de inicio")
#label_minutes.grid(row = 0,column = 0)

#label_minutes = tk.Label(ventana_input_time,text = "Segundos de inicio")
#label_minutes.grid(row = 1,column = 0)


#entry_var_minutes = tk.StringVar()
#entry_minutes =tk.Entry(textvariable=entry_var_minutes)
#entry_minutes.grid(row = 0,column = 1)

#entry_var_seconds = tk.StringVar()
#entry_seconds =tk.Entry(textvariable=entry_var_seconds)
#entry_seconds.grid(row = 1,column = 1)


#def confirm_time():
    
#    ventana_input_time.quit()
#    ventana_input_time.destroy()

#confirm_button = tk.Button(ventana_input_time,text = "Confirmar",command = confirm_time)
#confirm_button.grid(row = 2,column = 1)
#ventana_input_time.mainloop()




min_start_experiment = round(tiempo_inicio_edf//60)
sec_start_experiment = round(tiempo_inicio_edf%60,2)


time_start = min_start_experiment * 60 + sec_start_experiment


time0 = data[0]["time_stamps"][0] # inicio del experimento
aux = 0

  
i=0

str_aux = """"""
l = 0
for stream in data:
    y = stream['time_series']

    if isinstance(y, list):
       
        for timestamp, marker in zip(stream['time_stamps'], y):
                            
            abstimestamp = timestamp - time0
            
            if(abstimestamp-aux > 3): 
                
                #print(i,f'Marker "{marker[0]}" Duration of the pause: {abstimestamp-aux:.2f}')
               str_aux+="Instante de tiempo:"+str(int(time_start+aux)//60)+"'"+str(int(time_start+aux)%60)+"''"+"Duración de la pausa"+str( round((abstimestamp-aux),2))+"''"
               str_aux+="\n \n"
               l+=1
               if(l>5):break
            aux = abstimestamp
               
            i+=1

window_pauses = tk.Tk()

label_pauses = tk.Label(window_pauses,text = str_aux)
label_pauses.pack()
window_pauses.mainloop()
